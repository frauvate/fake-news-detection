"""
HÃ¼rriyet Manuel Crawler
------------------------
HÃ¼rriyet sitesinden HTML parsing ile haberleri Ã§eker.
RSS desteÄŸi olmadÄ±ÄŸÄ± iÃ§in anasayfa ve kategori sayfalarÄ±ndan Ã§ekiyor.

NOT: HÃ¼rriyet'in site yapÄ±sÄ± sÄ±k deÄŸiÅŸebilir, CSS selectorlarÄ± gÃ¼ncellenmeli
"""

import requests
from selectolax.parser import HTMLParser
from datetime import datetime
import time
from urllib.parse import urljoin

from config import REQUEST_TIMEOUT, USER_AGENT


def crawl_hurriyet():
    """
    HÃ¼rriyet anasayfasÄ±ndan haberleri Ã§eker
    
    Returns:
        list: Haber listesi (dict'lerden oluÅŸan)
    """
    print("\n  ğŸ” https://www.hurriyet.com.tr/")
    print("     â””â”€ HTML parsing ile Ã§ekiliyor...")
    
    base_url = "https://www.hurriyet.com.tr"
    haberler = []
    
    try:
        # User-Agent ekleyerek istek at
        headers = {"User-Agent": USER_AGENT}
        
        response = requests.get(base_url, headers=headers, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        
        # HTML'i parse et
        tree = HTMLParser(response.text)
        
        # HÃ¼rriyet'teki haber linklerini bul
        # NOT: Site yapÄ±sÄ± deÄŸiÅŸebilir, CSS selectorlarÄ± gÃ¼ncel tutulmalÄ±
        
        # YÃ¶ntem 1: TÃ¼m haber linklerini bul
        for link_element in tree.css("a"):
            href = link_element.attributes.get("href", "")
            
            # Sadece haber linklerini al (Ã¶rnek pattern)
            if not href or not any(x in href for x in ['/haber/', '/gundem/', '/ekonomi/', '/spor/']):
                continue
            
            # BaÅŸlÄ±k al (link iÃ§indeki metin veya title attribute)
            baslik = link_element.text(strip=True)
            if not baslik:
                baslik = link_element.attributes.get("title", "")
            
            # Ã‡ok kÄ±sa baÅŸlÄ±klarÄ± atla
            if not baslik or len(baslik) < 15:
                continue
            
            # Relative URL'i absolute yap
            if not href.startswith("http"):
                href = urljoin(base_url, href)
            
            # Duplicate kontrolÃ¼ (aynÄ± URL'yi 2 kez ekleme)
            if any(h["url"] == href for h in haberler):
                continue
            
            # Haber objesi oluÅŸtur
            haber = {
                "baslik": baslik.strip(),
                "ozet": None,  # Anasayfada Ã¶zet yok genelde
                "tarih": datetime.now(),
                "kaynak": "hurriyet",
                "url": href
            }
            
            haberler.append(haber)
            
            # Ã‡ok fazla haber eklenmesini Ã¶nle (her Ã§alÄ±ÅŸmada en fazla 50)
            if len(haberler) >= 50:
                break
        
        print(f"     â””â”€ âœ… {len(haberler)} haber bulundu")
        
    except requests.Timeout:
        print(f"     â””â”€ â±ï¸  Timeout!")
    except requests.RequestException as e:
        print(f"     â””â”€ âŒ HTTP hatasÄ±: {e}")
    except Exception as e:
        print(f"     â””â”€ âŒ Beklenmeyen hata: {e}")
    
    return haberler


def hurriyet_kategorileri_cek():
    """
    HÃ¼rriyet'in farklÄ± kategorilerinden haberleri Ã§eker
    
    Returns:
        list: TÃ¼m haberler
    """
    kategoriler = [
        "",  # Anasayfa
        "gundem",
        "ekonomi",
        "dunya",
        "teknoloji",
        "spor"
    ]
    
    tum_haberler = []
    
    for kategori in kategoriler:
        url = f"https://www.hurriyet.com.tr/{kategori}" if kategori else "https://www.hurriyet.com.tr"
        
        try:
            headers = {"User-Agent": USER_AGENT}
            response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
            tree = HTMLParser(response.text)
            
            for link_element in tree.css("a"):
                href = link_element.attributes.get("href", "")
                
                if not href or '/haber/' not in href:
                    continue
                
                baslik = link_element.text(strip=True)
                if not baslik or len(baslik) < 15:
                    continue
                
                if not href.startswith("http"):
                    href = f"https://www.hurriyet.com.tr{href}"
                
                # Duplicate kontrolÃ¼
                if any(h["url"] == href for h in tum_haberler):
                    continue
                
                haber = {
                    "baslik": baslik.strip(),
                    "ozet": None,
                    "tarih": datetime.now(),
                    "kaynak": "hurriyet",
                    "url": href
                }
                
                tum_haberler.append(haber)
            
            # Rate limiting
            time.sleep(2)
            
        except Exception as e:
            print(f"     â””â”€ âš ï¸  {kategori} kategorisi hata: {e}")
            continue
    
    return tum_haberler